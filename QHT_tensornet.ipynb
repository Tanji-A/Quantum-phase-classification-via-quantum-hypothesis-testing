{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QHT import QHT\n",
    "from exactqcnn_tensornet import ExactQcnnMPS\n",
    "from my_tensornetwork import MyFiniteMPS\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QHTMPS(QHT):\n",
    "    def __init__(self, exactqcnn:ExactQcnnMPS):\n",
    "        self.n_qubits = exactqcnn.n_qubits\n",
    "        self.exactqcnn = exactqcnn\n",
    "\n",
    "        # train1\n",
    "        read_data = self._dataset_Pollmann(\"train1\")\n",
    "        self.h1h2_i_train1 = read_data[0]\n",
    "        self.label_i_train1 = read_data[1] \n",
    "        # train2\n",
    "        read_data = self._dataset_Pollmann(\"train2\")\n",
    "        self.h1h2_i_train2 = read_data[0]\n",
    "        self.label_i_train2 = read_data[1] \n",
    "        # test1\n",
    "        read_data = self._dataset_Pollmann(\"test1\")\n",
    "        self.h1h2_i_test1 = read_data[0]\n",
    "        self.label_i_test1 = read_data[1]\n",
    "        # test2\n",
    "        read_data = self._dataset_Pollmann(\"test2\")\n",
    "        self.h1h2_i_test2 = read_data[0]\n",
    "        self.label_i_test2 = read_data[1]\n",
    "\n",
    "\n",
    "    def calc_error_separable_OP(self, n, alpha_min_li=[0.25], read_json=True, data=\"test1\", mode=\"bayes\"):\n",
    "        folder_dmrg = \"./tensornetPollmann/results\"\n",
    "\n",
    "        if data==\"test1\":\n",
    "            J1J2_i = self.h1h2_i_test1\n",
    "            label_i = self.label_i_test1\n",
    "        elif data==\"test2\":\n",
    "            J1J2_i = self.h1h2_i_test2\n",
    "            label_i = self.label_i_test2\n",
    "\n",
    "        if not read_json:\n",
    "            raise Exception(f\"Please calculate OP_Pollmann in {folder_dmrg}.\")\n",
    "        else:\n",
    "            if data==\"test1\":\n",
    "                # with open(f\"./json_data/OP(L={self.n_qubits},{data})_ave_Z.json\") as f:\n",
    "                #     json_dict = json.load(f)\n",
    "                # J1J2_json = json_dict[\"J1J2\"]\n",
    "                # ave_OP_json = json_dict[\"ave_Z\"]\n",
    "                # ave_OP_nt = np.mean(np.abs(np.array(ave_OP_json))[label_i==2])\n",
    "                # ave_OP_tri = np.mean(np.abs(np.array(ave_OP_json))[label_i==0])\n",
    "                return self.calc_error_separable_OP_FMz(n, alpha_min_li, read_json, data, mode)\n",
    "            elif data==\"test2\":\n",
    "                with open(f\"./json_data/OP(L={self.n_qubits},{data})_ave_SOP.json\") as f:\n",
    "                    json_dict = json.load(f)\n",
    "                J1J2_json = json_dict[\"J1J2\"]\n",
    "                ave_OP_json = json_dict[\"ave_SOP\"]\n",
    "                ave_OP_nt = np.mean(np.array(ave_OP_json)[label_i==1])\n",
    "                ave_OP_tri = np.mean(np.array(ave_OP_json)[label_i==0])\n",
    "            assert np.allclose(np.array(J1J2_json), J1J2_i)    \n",
    "\n",
    "        bernoulli_p_nt = (ave_OP_nt+1)/2\n",
    "        bernoulli_p_tri = (ave_OP_tri+1)/2\n",
    "\n",
    "        # 尤度比検定: 手書きメモ参照\n",
    "        nCr = math.comb\n",
    "        n_is_int = type(n) == int\n",
    "        if n_is_int:\n",
    "            n_li = [n]\n",
    "        else:\n",
    "            n_li = n\n",
    "        result_li = []\n",
    "        for n in n_li:\n",
    "            # k_alphaを見つけ、gammaも求める\n",
    "            k_alpha_li = []\n",
    "            gamma_li = []\n",
    "            for alpha_min in alpha_min_li:\n",
    "                F = 0\n",
    "                for k in range(n+1):\n",
    "                    f = nCr(n, k) * 0.5**n\n",
    "                    F += f\n",
    "                    if alpha_min >= 1-F:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "                        break\n",
    "                    elif k==n:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "            # alphaとbetaを求める\n",
    "            alpha_li = []\n",
    "            beta_li = []\n",
    "            for i, k_alpha in enumerate(k_alpha_li): \n",
    "                alpha = 1- sum([nCr(n,j)*bernoulli_p_tri**j*(1-bernoulli_p_tri)**(n-j) for j in range(k_alpha+1)])\n",
    "                alpha += gamma_li[i] * nCr(n,k_alpha)*bernoulli_p_tri**k_alpha*(1-bernoulli_p_tri)**(n-k_alpha)\n",
    "                alpha_li.append(alpha)\n",
    "                beta = sum([nCr(n,j)*bernoulli_p_nt**j*(1-bernoulli_p_nt)**(n-j) for j in range(k_alpha)])\n",
    "                beta += (1-gamma_li[i]) * nCr(n,k_alpha)*bernoulli_p_nt**k_alpha*(1-bernoulli_p_nt)**(n-k_alpha)\n",
    "                beta_li.append(beta)\n",
    "            result_li.append((alpha_li, beta_li))\n",
    "        if n_is_int:\n",
    "            return result_li[0]\n",
    "        else:\n",
    "            return result_li\n",
    "        \n",
    "    def gen_qNeyman(self, seed=None, a=0, a_li=None, shots=20*300*2, n_ent=3, data=\"train1\", haar=\"haar\"):\n",
    "        self.shots = shots\n",
    "        assert self.shots%20==0\n",
    "\n",
    "        if data==\"train1\":\n",
    "            J1J2_i = self.h1h2_i_train1\n",
    "            label_i = self.label_i_train1\n",
    "        elif data==\"train2\":\n",
    "            J1J2_i = self.h1h2_i_train2\n",
    "            label_i = self.label_i_train2\n",
    "\n",
    "        folder = f\"./random_unitary/random_{haar}/\"\n",
    "        folder_dmrg = \"./tensornetPollmann/results\"\n",
    "        \n",
    "        rng = np.random.default_rng(seed)\n",
    "        file_idx = 1\n",
    "        remained_random = np.load(folder+f\"{n_ent}qubits_40x2x10000num({file_idx}).npy\")\n",
    "        remained_random2 = None\n",
    "        rho_hat_li_nt = [0 for _ in range(0,self.n_qubits,n_ent)]\n",
    "        rho_hat_li_tri = [0 for _ in range(0,self.n_qubits,n_ent)]\n",
    "        \n",
    "        for npz_path in tqdm(os.listdir(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}\"), leave=False):\n",
    "            match = re.search(r'J1=(-?\\d+\\.?\\d*e?-?\\d*),J2=(-?\\d+\\.?\\d*e?-?\\d*)', npz_path)\n",
    "            J1J2 = [float(match.group(1)), float(match.group(2))]\n",
    "            match = np.isclose(J1J2_i,J1J2)\n",
    "            match = np.where(match[:,0]&match[:,1])[0]\n",
    "            if match.shape[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                label = label_i[match[0]]\n",
    "            for _ in tqdm(range(self.shots//20), leave=False):\n",
    "                mps = MyFiniteMPS([arr.astype(np.complex128) for arr in list(np.load(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}/{npz_path}\").values())])\n",
    "                for i_q, qidx in enumerate(range(0,self.n_qubits,n_ent)):\n",
    "                    if qidx+n_ent <= self.n_qubits:\n",
    "                        _n = n_ent\n",
    "                        while remained_random.shape[0] < 1:\n",
    "                            file_idx += 1\n",
    "                            try:\n",
    "                                remained_random = np.concatenate([remained_random, np.load(folder+f\"{n_ent}qubits_40x2x10000num({file_idx}).npy\")])\n",
    "                            except FileNotFoundError:\n",
    "                                file_idx = 1\n",
    "                                remained_random = np.concatenate([remained_random, np.load(folder+f\"{n_ent}qubits_40x2x10000num({file_idx}).npy\")])\n",
    "                        choice_haar = remained_random[0]\n",
    "                        remained_random = remained_random[1:]\n",
    "                    else:\n",
    "                        _n = self.n_qubits-qidx\n",
    "                        file_idx2 = 1\n",
    "                        if remained_random2 is None:\n",
    "                            remained_random2 = np.load(folder+f\"{_n}qubits_40x2x10000num({file_idx2}).npy\")\n",
    "                        while remained_random2.shape[0] < 1:\n",
    "                            file_idx2 += 1\n",
    "                            try:\n",
    "                                remained_random2 = np.concatenate([remained_random2, np.load(folder+f\"{_n}qubits_40x2x10000num({file_idx2}).npy\")])\n",
    "                            except FileNotFoundError:\n",
    "                                file_idx2 = 1\n",
    "                                remained_random2 = np.concatenate([remained_random2, np.load(folder+f\"{_n}qubits_40x2x10000num({file_idx2}).npy\")])\n",
    "                        choice_haar = remained_random2[0]\n",
    "                        remained_random2 = remained_random2[1:]\n",
    "                    if _n==3:\n",
    "                        meas_li = []\n",
    "                        for i in range(2**_n):\n",
    "                            op = choice_haar.T.conj()[:,i][:,None]@choice_haar[i][None,:]\n",
    "                            meas_li.append(mps.measure_three_site_observable(op.reshape([2 for _ in range(int(2*_n))]), qidx,qidx+1,qidx+2).real)\n",
    "                    elif _n==2:\n",
    "                        meas_li = []\n",
    "                        for i in range(2**_n):\n",
    "                            op = choice_haar.T.conj()[:,i][:,None]@choice_haar[i][None,:]\n",
    "                            meas_li.append(mps.measure_two_site_observable(op.reshape([2 for _ in range(int(2*_n))]), qidx,qidx+1).real)\n",
    "                    elif _n==1:\n",
    "                        meas_li = []\n",
    "                        for i in range(2**_n):\n",
    "                            op = choice_haar.T.conj()[:,i][:,None]@choice_haar[i][None,:]\n",
    "                            meas_li.append(mps.measure_local_operator([op.reshape([2 for _ in range(int(2*_n))])], [qidx])[0].real)\n",
    "                    else:\n",
    "                        raise Exception(\"It has not supported yet!\")\n",
    "                    meas_int = rng.choice(len(meas_li), p=meas_li)\n",
    "                    snapshot = (2**_n+1) * choice_haar.T.conj()[:,meas_int][:,None]@choice_haar[meas_int][None,:] - np.eye(2**_n)\n",
    "                    if label==0:\n",
    "                        rho_hat_li_tri[i_q] += snapshot\n",
    "                    else:\n",
    "                        rho_hat_li_nt[i_q] += snapshot\n",
    "        for i, qidx in enumerate(range(0,self.n_qubits,n_ent)):\n",
    "            rho_hat_li_tri[i] /= np.count_nonzero(label_i==0)\n",
    "            rho_hat_li_nt[i] /= np.count_nonzero(label_i!=0)\n",
    "\n",
    "        if a_li is None:\n",
    "            vv_li = []\n",
    "            uu_li = []\n",
    "            for rho_nt, rho_tri in zip(rho_hat_li_nt, rho_hat_li_tri):\n",
    "                vv, uu = np.linalg.eigh(rho_tri - np.exp(a)*rho_nt)\n",
    "                vv_li.append(vv)\n",
    "                uu_li.append(uu)\n",
    "            self.qNeyman_hat = [[vv_li, uu_li]]\n",
    "        else:\n",
    "            self.qNeyman_hat = []\n",
    "            for a in tqdm(a_li, leave=False):\n",
    "                vv_li = []\n",
    "                uu_li = []\n",
    "                for rho_nt, rho_tri in zip(rho_hat_li_nt, rho_hat_li_tri):\n",
    "                    vv, uu = np.linalg.eigh(rho_tri - np.exp(a)*rho_nt)\n",
    "                    vv_li.append(vv)\n",
    "                    uu_li.append(uu)\n",
    "                self.qNeyman_hat.append([vv_li, uu_li])\n",
    "\n",
    "        return \n",
    "    \n",
    "    def multi_func1(self, multi_input):\n",
    "        prob = 0\n",
    "        meas_li = multi_input[1]\n",
    "        multi_input = multi_input[0]\n",
    "        for basis_idx in multi_input:\n",
    "            basis_idx = format(basis_idx, '0' + str(self.n_qubits) + 'b')\n",
    "            basis_idx = np.array([int(x) for x in basis_idx], dtype=bool)\n",
    "            prob += np.prod(np.hstack([meas_li[~basis_idx], (1-meas_li[basis_idx])]))\n",
    "        return prob\n",
    "    def calc_error_separable_CSqNeyman(self, n, seed=None, a_li=[0], shots=20*300*2, \n",
    "                                       n_ent=3, data=\"test1\", haar=\"haar\",\n",
    "                                       read_json=True, read_npz=True):\n",
    "        folder_dmrg = \"./tensornetPollmann/results\"\n",
    "        if data==\"test1\":\n",
    "            J1J2_i = self.h1h2_i_test1\n",
    "            label_i = self.label_i_test1\n",
    "            data_train = \"train1\"\n",
    "        elif data==\"test2\":\n",
    "            J1J2_i = self.h1h2_i_test2\n",
    "            label_i = self.label_i_test2\n",
    "            data_train = \"train2\"\n",
    "        elif data==\"train1\":\n",
    "            J1J2_i = self.h1h2_i_train1\n",
    "            label_i = self.label_i_train1\n",
    "            data_train = \"train1\"\n",
    "\n",
    "        if not read_json:\n",
    "            if read_npz:\n",
    "                folder_npz = f\"./npz_data/CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent})/\"\n",
    "                assert (np.array(a_li) == np.load(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_a_li.npy\")).all()\n",
    "                qNeyman_hat = []\n",
    "                vv_li_li = np.load(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_vv_li.npz\").values()\n",
    "                uu_li_li = np.load(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_uu_li.npz\").values()\n",
    "                num_dev = math.ceil(self.n_qubits/n_ent)\n",
    "                vv_li_li = [x for x in vv_li_li]\n",
    "                vv_li_li = [vv_li_li[i:i+num_dev] for i in range(0,len(vv_li_li),num_dev)]\n",
    "                uu_li_li = [x for x in uu_li_li]\n",
    "                uu_li_li = [uu_li_li[i:i+num_dev] for i in range(0,len(uu_li_li),num_dev)]\n",
    "                for vv_li, uu_li in zip(vv_li_li, uu_li_li):\n",
    "                    qNeyman_hat.append([vv_li, uu_li])\n",
    "                self.qNeyman_hat = qNeyman_hat\n",
    "                qNeyman_hat=None; vv_li_li=None; uu_li_li=None\n",
    "            else:\n",
    "                self.gen_qNeyman(seed, a_li=a_li, shots=shots, n_ent=n_ent, data=data_train, haar=haar)\n",
    "                folder_npz = f\"./CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent})/\"\n",
    "                os.makedirs(folder_npz)\n",
    "                np.save(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_a_li.npy\", a_li)\n",
    "                np.savez_compressed(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_vv_li.npz\", *sum([x[0] for x in self.qNeyman_hat],[]))\n",
    "                np.savez_compressed(folder_npz+f\"CSqNeyman(L={self.n_qubits}_shots={shots}_seed={seed}_nent={n_ent},{data_train}{','+haar if haar!='haar' else ''})_uu_li.npz\", *sum([x[1] for x in self.qNeyman_hat],[]))\n",
    "\n",
    "            rng = np.random.default_rng()\n",
    "            alpha_li = [0 for _ in range(len(a_li))]\n",
    "            beta_li = [0 for _ in range(len(a_li))]\n",
    "            for npz_path in tqdm(os.listdir(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}\"), leave=False):\n",
    "                match = re.search(r'J1=(-?\\d+\\.?\\d*e?-?\\d*),J2=(-?\\d+\\.?\\d*e?-?\\d*)', npz_path)\n",
    "                J1J2 = [float(match.group(1)), float(match.group(2))]\n",
    "                match = np.isclose(J1J2_i,J1J2)\n",
    "                match = np.where(match[:,0]&match[:,1])[0]\n",
    "                if match.shape[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    label = label_i[match[0]]\n",
    "                for i_a, a in enumerate(a_li):\n",
    "                    if a!=0:\n",
    "                        continue\n",
    "                    mps = MyFiniteMPS([arr.astype(np.complex128) for arr in list(np.load(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}/{npz_path}\").values())])\n",
    "                    meas_li = []\n",
    "                    qidx = 0\n",
    "                    for uu in self.qNeyman_hat[i_a][1]:\n",
    "                        if uu.shape[0]==2**3:\n",
    "                            li = []\n",
    "                            for i in range(2**3):\n",
    "                                op = uu[:,i][:,None]@uu.T.conj()[i][None,:]\n",
    "                                li.append(mps.measure_three_site_observable(op.reshape([2 for _ in range(int(2*3))]), qidx,qidx+1,qidx+2).real)\n",
    "                            meas_li.append(li)\n",
    "                            qidx += 3\n",
    "                        elif uu.shape[0]==2**2:\n",
    "                            li = []\n",
    "                            for i in range(2**2):\n",
    "                                op = uu[:,i][:,None]@uu.T.conj()[i][None,:]\n",
    "                                li.append(mps.measure_two_site_observable(op.reshape([2 for _ in range(int(2*2))]), qidx,qidx+1).real)\n",
    "                            meas_li.append(li)\n",
    "                            qidx += 2  \n",
    "                        elif uu.shape[0]==2**1:\n",
    "                            li = []\n",
    "                            for i in range(2**1):\n",
    "                                op = uu[:,i][:,None]@uu.T.conj()[i][None,:]\n",
    "                                li.append(mps.measure_local_operator([op.reshape([2 for _ in range(int(2*1))])], [qidx])[0].real)\n",
    "                            meas_li.append(li)\n",
    "                            qidx += 1   \n",
    "                        else:\n",
    "                            raise Exception(\"It has not supported yet!\")\n",
    "                    # #multicpt\n",
    "                    # num_div = len(self.qNeyman_hat[i][1])//(cpu_count()-1)\n",
    "                    # with Pool(cpu_count()-1) as p:\n",
    "                    #     multi_output_li = p.map(self.multi_func1, [(self.qNeyman_hat[i][1][j:j+num_div], meas_li) for j in range(0,len(self.qNeyman_hat[i][1]),num_div)])\n",
    "                    # prob = sum(multi_output_li)\n",
    "                    # #singlecpu\n",
    "                    # prob = 0\n",
    "                    # for basis_idx in self.qNeyman_hat[i][1]:\n",
    "                    #     basis_idx = format(basis_idx, '0' + str(self.n_qubits) + 'b')\n",
    "                    #     basis_idx = np.array([int(x) for x in basis_idx], dtype=bool)\n",
    "                    #     prob += np.prod(np.hstack([meas_li[~basis_idx], (1-meas_li[basis_idx])]))\n",
    "                    max_length = max(len(sublist) for sublist in meas_li) # zero padding (for transforming list to array)\n",
    "                    meas_li = np.array([sublist + [0] * (max_length - len(sublist)) for sublist in meas_li])\n",
    "                    max_length = max(len(sublist) for sublist in self.qNeyman_hat[i_a][0])\n",
    "                    vv_li = np.array([sublist.tolist() + [0] * (max_length - len(sublist)) for sublist in self.qNeyman_hat[i_a][0]])\n",
    "                    K = int(1e+7)\n",
    "                    sample_li = np.array([rng.choice(meas_li.shape[1], size=K, p=probabilities) for probabilities in meas_li])\n",
    "                    selected_values = vv_li[np.arange(meas_li.shape[0])[:, None], sample_li]\n",
    "                    # product_values = np.prod(selected_values, axis=0)\n",
    "                    # positive_prob = np.count_nonzero(product_values > 0)/K\n",
    "                    positive_count = np.sum(selected_values>0, axis=0)\n",
    "                    positive_prob = np.count_nonzero(positive_count > meas_li.shape[0]//2)/K\n",
    "                    if label==0:\n",
    "                        alpha_li[i_a] += positive_prob\n",
    "                    else:\n",
    "                        beta_li[i_a] += positive_prob\n",
    "            alpha_li = 1 - np.array(alpha_li)/np.count_nonzero(label_i==0)\n",
    "            beta_li = np.array(beta_li)/np.count_nonzero(label_i!=0)\n",
    "            \n",
    "            self.alpha_li = alpha_li; self.beta_li = beta_li\n",
    "            with open(f\"./CSqNeyman(L={self.n_qubits}_shots={shots}_nent={n_ent},{data}{','+haar if haar!='haar' else ''})_alphabeta.json\", \"w\") as f:\n",
    "                json.dump({\"a_li\":a_li, \"alpha\":alpha_li.tolist(), \"beta\":beta_li.tolist()}, f, indent=2)\n",
    "\n",
    "        else:\n",
    "            with open(f\"./json_data/CSqNeyman(L={self.n_qubits}_shots={shots}_nent={n_ent},{data}{','+haar if haar!='haar' else ''})_alphabeta.json\") as f:\n",
    "                json_dict = json.load(f)\n",
    "            assert (np.array(a_li) == np.array(json_dict[\"a_li\"])).all()\n",
    "            alpha_li = np.array(json_dict[\"alpha\"])\n",
    "            beta_li = np.array(json_dict[\"beta\"])\n",
    "\n",
    "        n_is_int = type(n) == int\n",
    "        if n_is_int:\n",
    "            n_li = [n]\n",
    "        else:\n",
    "            n_li = n\n",
    "        result_li = []\n",
    "        for n in n_li:\n",
    "            if n>1:\n",
    "                nCr = math.comb\n",
    "                # (1-alpha)よりalphaの方を多く得る確率=alpha_n\n",
    "                alpha_n_li = np.sum([nCr(n, r)*alpha_li**(n-r)*(1-alpha_li)**r for r in range(n//2+1)], axis=0)\n",
    "                beta_n_li = np.sum([nCr(n, r)*beta_li**(n-r)*(1-beta_li)**r for r in range(n//2+1)], axis=0)\n",
    "                # 古典Neyman-Pearsonでいうgamma=0.5なので、足し過ぎた分引く\n",
    "                if n%2 == 0:\n",
    "                    alpha_n_li -= 0.5 * nCr(n,n//2)*alpha_li**(n//2)*(1-alpha_li)**(n//2)\n",
    "                    beta_n_li -= 0.5 * nCr(n,n//2)*beta_li**(n//2)*(1-beta_li)**(n//2)\n",
    "            elif n==1:\n",
    "                alpha_n_li = alpha_li; beta_n_li = beta_li\n",
    "            result_li.append((alpha_n_li.tolist(), beta_n_li.tolist()))\n",
    "        if n_is_int:\n",
    "            return result_li[0]\n",
    "        else:\n",
    "            return result_li \n",
    "        \n",
    "    def calc_error_separable_qcnn(self, n, shots_per_rho=None, index=150,\n",
    "                                  alpha_min_li=[0.25],\n",
    "                                  read_json=True, data=\"test1\",\n",
    "                                  qcnn_mode=\"qcnn1\"):\n",
    "        if data==\"test1\":\n",
    "            J1J2_i = self.h1h2_i_test1\n",
    "            label_i = self.label_i_test1\n",
    "        elif data==\"test2\":\n",
    "            J1J2_i = self.h1h2_i_test2\n",
    "            label_i = self.label_i_test2\n",
    "\n",
    "        if not read_json:\n",
    "            raise Exception(f\"Please calculate qcnn_Pollmann in this directory.\")\n",
    "        else:\n",
    "            with open(f\"./json_data/{qcnn_mode}(L={self.n_qubits}_shots={shots_per_rho},{data}).json\") as f:\n",
    "                json_dict = json.load(f)\n",
    "            ave_qcnn_json = json_dict[\"expectation_list\"][f\"index={index}\"]\n",
    "            ave_qcnn_nt = np.mean(np.array(ave_qcnn_json)[label_i!=0])\n",
    "            ave_qcnn_tri = np.mean(np.array(ave_qcnn_json)[label_i==0])\n",
    "\n",
    "        if \"qcnn1\" in qcnn_mode:\n",
    "            p0 = 3/4\n",
    "        elif \"qcnn2\" in qcnn_mode:\n",
    "            p0 = 1/2\n",
    "\n",
    "        bernoulli_p_nt = (ave_qcnn_nt+1)/2\n",
    "        bernoulli_p_tri = (ave_qcnn_tri+1)/2\n",
    "\n",
    "        # 尤度比検定: 手書きメモ参照\n",
    "        nCr = math.comb\n",
    "        n_is_int = type(n) == int\n",
    "        if n_is_int:\n",
    "            n_li = [n]\n",
    "        else:\n",
    "            n_li = n\n",
    "        result_li = []\n",
    "        for n in n_li:\n",
    "            # k_alphaを見つけ、gammaも求める\n",
    "            k_alpha_li = []\n",
    "            gamma_li = []\n",
    "            for alpha_min in alpha_min_li:\n",
    "                F = 0\n",
    "                for k in range(n+1):\n",
    "                    f = nCr(n, k) * p0**k*(1-p0)**(n-k)\n",
    "                    F += f\n",
    "                    if alpha_min >= 1-F:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "                        break\n",
    "                    elif k==n:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "            # alphaとbetaを求める\n",
    "            alpha_li = []\n",
    "            beta_li = []\n",
    "            for i, k_alpha in enumerate(k_alpha_li): \n",
    "                alpha = 1- sum([nCr(n,j)*bernoulli_p_tri**j*(1-bernoulli_p_tri)**(n-j) for j in range(k_alpha+1)])\n",
    "                alpha += gamma_li[i] * nCr(n,k_alpha)*bernoulli_p_tri**k_alpha*(1-bernoulli_p_tri)**(n-k_alpha)\n",
    "                alpha_li.append(alpha)\n",
    "                beta = sum([nCr(n,j)*bernoulli_p_nt**j*(1-bernoulli_p_nt)**(n-j) for j in range(k_alpha)])\n",
    "                beta += (1-gamma_li[i]) * nCr(n,k_alpha)*bernoulli_p_nt**k_alpha*(1-bernoulli_p_nt)**(n-k_alpha)\n",
    "                beta_li.append(beta)\n",
    "            result_li.append((alpha_li, beta_li))\n",
    "        if n_is_int:\n",
    "            return result_li[0]\n",
    "        else:\n",
    "            return result_li\n",
    "        \n",
    "    def calc_error_separable_exactqcnn(self, n, alpha_min_li=[0.25], read_json=True, data=\"test1\"):\n",
    "        folder_dmrg = \"./tensornetPollmann/results\"\n",
    "\n",
    "        if data==\"train1\":\n",
    "            J1J2_i = self.h1h2_i_train1\n",
    "            label_i = self.label_i_train1 \n",
    "        elif data==\"train2\":\n",
    "            J1J2_i = self.h1h2_i_train2\n",
    "            label_i = self.label_i_train2  \n",
    "        elif data==\"test1\":\n",
    "            J1J2_i = self.h1h2_i_test1\n",
    "            label_i = self.label_i_test1\n",
    "        elif data==\"test2\":\n",
    "            J1J2_i = self.h1h2_i_test2\n",
    "            label_i = self.label_i_test2\n",
    "\n",
    "        if not read_json:\n",
    "            meas_li = [None for _ in range(len(J1J2_i))]\n",
    "            for npz_path in tqdm(os.listdir(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}\"), leave=False):\n",
    "                match = re.search(r'J1=(-?\\d+\\.?\\d*e?-?\\d*),J2=(-?\\d+\\.?\\d*e?-?\\d*)', npz_path)\n",
    "                J1J2 = [float(match.group(1)), float(match.group(2))]\n",
    "                match = np.isclose(J1J2_i,J1J2)\n",
    "                match = np.where(match[:,0]&match[:,1])[0]\n",
    "                if match.shape[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    label = label_i[match[0]]\n",
    "                mps = MyFiniteMPS(list(np.load(folder_dmrg+f\"/dmrg_Pollmann_{data}/L={self.n_qubits}/{npz_path}\").values()))\n",
    "                if data==\"test1\" or data==\"train1\":\n",
    "                    meas = self.exactqcnn.meas_Z(mps) # exactqcnnにcomplexが無いので,mpsもfloatで良い\n",
    "                elif data==\"test2\" or data==\"train2\":\n",
    "                    meas = self.exactqcnn.meas_SOP(mps) # exactqcnnにcomplexが無いので,mpsもfloatで良い\n",
    "                meas_li[match[0]] = meas\n",
    "            if data==\"test1\" or data==\"train1\":\n",
    "                with open(f\"./exactqcnn(L={self.n_qubits},{data})_ave_Z.json\", \"w\") as f:\n",
    "                    json.dump({\"J1J2\":np.array(J1J2_i).tolist(), \"ave_Z\":meas_li}, f, indent=2)\n",
    "            elif data==\"test2\" or data==\"train2\":\n",
    "                with open(f\"./exactqcnn(L={self.n_qubits},{data})_ave_SOP.json\", \"w\") as f:\n",
    "                    json.dump({\"J1J2\":np.array(J1J2_i).tolist(), \"ave_SOP\":meas_li}, f, indent=2)\n",
    "            ave_exactqcnn_nt = np.mean(np.array(meas_li)[label_i!=0])\n",
    "            ave_exactqcnn_tri = np.mean(np.array(meas_li)[label_i==0])\n",
    "        else:\n",
    "            if data==\"test1\" or data==\"train1\":\n",
    "                with open(f\"./json_data/exactqcnn(L={self.n_qubits},{data})_ave_Z.json\") as f:\n",
    "                    json_dict = json.load(f)\n",
    "                J1J2_json = json_dict[\"J1J2\"]\n",
    "                ave_exactqcnn_json = json_dict[\"ave_Z\"]\n",
    "                ave_exactqcnn_nt = np.mean(np.array(ave_exactqcnn_json)[label_i!=0])\n",
    "                ave_exactqcnn_tri = np.mean(np.array(ave_exactqcnn_json)[label_i==0])\n",
    "            elif data==\"test2\" or data==\"train2\":\n",
    "                with open(f\"./json_data/exactqcnn(L={self.n_qubits},{data})_ave_SOP.json\") as f:\n",
    "                    json_dict = json.load(f)\n",
    "                J1J2_json = json_dict[\"J1J2\"]\n",
    "                ave_exactqcnn_json = json_dict[\"ave_SOP\"]\n",
    "                ave_exactqcnn_nt = np.mean(np.array(ave_exactqcnn_json)[label_i!=0])\n",
    "                ave_exactqcnn_tri = np.mean(np.array(ave_exactqcnn_json)[label_i==0])\n",
    "            assert np.allclose(np.array(J1J2_json), J1J2_i)\n",
    "\n",
    "        p0 = 3/4\n",
    "\n",
    "        bernoulli_p_nt = (ave_exactqcnn_nt+1)/2\n",
    "        bernoulli_p_tri = (ave_exactqcnn_tri+1)/2\n",
    "\n",
    "        # 尤度比検定: 手書きメモ参照\n",
    "        nCr = math.comb\n",
    "        n_is_int = type(n) == int\n",
    "        if n_is_int:\n",
    "            n_li = [n]\n",
    "        else:\n",
    "            n_li = n\n",
    "        result_li = []\n",
    "        for n in n_li:\n",
    "            # k_alphaを見つけ、gammaも求める\n",
    "            k_alpha_li = []\n",
    "            gamma_li = []\n",
    "            for alpha_min in alpha_min_li:\n",
    "                F = 0\n",
    "                for k in range(n+1):\n",
    "                    f = nCr(n, k) * p0**k*(1-p0)**(n-k)\n",
    "                    F += f\n",
    "                    if alpha_min >= 1-F:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "                        break\n",
    "                    elif k==n:\n",
    "                        k_alpha_li.append(k)\n",
    "                        gamma_li.append((alpha_min-1+F)/f)\n",
    "            # alphaとbetaを求める\n",
    "            alpha_li = []\n",
    "            beta_li = []\n",
    "            for i, k_alpha in enumerate(k_alpha_li): \n",
    "                alpha = 1- sum([nCr(n,j)*bernoulli_p_tri**j*(1-bernoulli_p_tri)**(n-j) for j in range(k_alpha+1)])\n",
    "                alpha += gamma_li[i] * nCr(n,k_alpha)*bernoulli_p_tri**k_alpha*(1-bernoulli_p_tri)**(n-k_alpha)\n",
    "                alpha_li.append(alpha)\n",
    "                beta = sum([nCr(n,j)*bernoulli_p_nt**j*(1-bernoulli_p_nt)**(n-j) for j in range(k_alpha)])\n",
    "                beta += (1-gamma_li[i]) * nCr(n,k_alpha)*bernoulli_p_nt**k_alpha*(1-bernoulli_p_nt)**(n-k_alpha)\n",
    "                beta_li.append(beta)\n",
    "            result_li.append((alpha_li, beta_li))\n",
    "        if n_is_int:\n",
    "            return result_li[0]\n",
    "        else:\n",
    "            return result_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactqcnn = ExactQcnnMPS(27, max_singular_values=200, max_truncation_err2=2e-5)\n",
    "ins = QHTMPS(exactqcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.calc_error_separable_CSqNeyman(n=1, seed=2, \n",
    "                                   a_li=[i/10 for i in range(-10,11)],shots=20*60*2, \n",
    "                                   n_ent=3, data=\"test2\", haar=\"haar\",\n",
    "                                   read_json=False,read_npz=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotData:\n",
    "    def __init__(self, qht:QHTMPS):\n",
    "        self.qht = qht\n",
    "        self.results_list_alpha_vs_beta = []\n",
    "        self.results_list_n_vs_logbeta = []\n",
    "        self.results_list_beta_vs_n = []\n",
    "        self.results_list_shots_vs_n = [] \n",
    "    def get_results_alpha_vs_beta(self, n, data=\"test1\"):\n",
    "        results_error_li = []\n",
    "        results_error_point = []\n",
    "        settings_dict = []\n",
    "        results_error_li.append(self.qht.calc_error_separable_OP(n, alpha_min_li=[i/100 for i in range(1,100)],\n",
    "                                                                 read_json=True, data=data))\n",
    "        settings_dict.append({\"color\":\"b\",\"linestyle\":\"-\",\"label\":\"cNeyman(OP)\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_CSqNeyman(n, seed=2, \n",
    "                                a_li=[i/10 for i in range(-10,11)],shots=20*15*2, \n",
    "                                n_ent=3, data=data,\n",
    "                                read_json=True,read_npz=False))\n",
    "        settings_dict.append({\"color\":\"brown\",\"marker\":\".\",\"linestyle\":\"--\",\"label\":\"tomography\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_qcnn(n, shots_per_rho=None,\n",
    "                                                                   alpha_min_li=[i/100 for i in range(1,100)],\n",
    "                                                                   index=150, read_json=True, data=data,\n",
    "                                                                   qcnn_mode=\"qcnn1\"))\n",
    "        settings_dict.append({\"color\":\"m\",\"linestyle\":\"-\",\"label\":\"qcnn\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_exactqcnn(n, alpha_min_li=[i/100 for i in range(1,100)], read_json=True, data=data))\n",
    "        settings_dict.append({\"color\":\"g\",\"linestyle\":\"-\",\"label\":\"exactqcnn\"})\n",
    "        self.results_list_alpha_vs_beta.append([n, results_error_li, results_error_point, settings_dict])\n",
    "    def get_results_beta_vs_n(self, n_max, data=\"test1\"):\n",
    "        n_li = list(range(1,n_max+1))\n",
    "        results_error_li = []\n",
    "        results_error_point = []\n",
    "        settings_dict = []\n",
    "        results_error_li.append(self.qht.calc_error_separable_OP(n_li, alpha_min_li=[i/500 for i in range(1,500)],\n",
    "                                                                 read_json=True, data=data))\n",
    "        settings_dict.append({\"color\":\"b\", \"linestyle\":\"\", \"marker\":\".\", \"label\":\"cNeyman(OP)\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_CSqNeyman(n_li, seed=2, \n",
    "                                a_li=[i/10 for i in range(-10,11)],shots=20*15*2,\n",
    "                                n_ent=3, data=data,\n",
    "                                read_json=True,read_npz=True))\n",
    "        settings_dict.append({\"color\":\"brown\", \"linestyle\":\"\", \"marker\":\".\", \"label\":\"tomography\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_qcnn(n_li, shots_per_rho=None, \n",
    "                                                                   alpha_min_li=[i/500 for i in range(1,500)],\n",
    "                                                                   index=150, read_json=True, data=data,\n",
    "                                                                   qcnn_mode=\"qcnn1\"))\n",
    "        settings_dict.append({\"color\":\"m\", \"linestyle\":\"\", \"marker\":\".\", \"label\":\"qcnn\"})\n",
    "        results_error_li.append(self.qht.calc_error_separable_exactqcnn(n_li, alpha_min_li=[i/500 for i in range(1,500)], read_json=True, data=data))\n",
    "        settings_dict.append({\"color\":\"g\", \"linestyle\":\"\", \"marker\":\".\", \"label\":\"exactqcnn\"})\n",
    "        self.results_list_beta_vs_n.append([results_error_li, results_error_point, settings_dict])\n",
    "    def get_results_shots_vs_n(self, n_max, data=\"test1\"):\n",
    "        n_li = list(range(1,n_max+1))\n",
    "        shots_li = []\n",
    "        results_error_li = []\n",
    "        results_error_point = []\n",
    "        settings_dict = []\n",
    "        shots_li.append([320,600,1200,2400])\n",
    "        results_error_li.append([self.qht.calc_error_separable_CSqNeyman(n_li, seed=2, \n",
    "                                a_li=[i/10 for i in range(-10,11)], shots=shots,\n",
    "                                n_ent=2, data=data,\n",
    "                                read_json=True,read_npz=True) for shots in shots_li[-1]])\n",
    "        settings_dict.append({\"color\":\"brown\", \"linestyle\":\"--\", \"marker\":\"o\", \"label\":\"tomography\"})\n",
    "        # shots_per_rho = 500\n",
    "        # shots_li.append([i*20*shots_per_rho*2 for i in [150]])\n",
    "        # results_error_point.append([self.qht.calc_error_separable_qcnn(n_li, shots_per_rho=shots_per_rho, \n",
    "        #                                                               index=shots//(20*shots_per_rho*2), read_json=True, data=data,\n",
    "        #                                                               qcnn_mode=\"qcnn2\") for shots in shots_li[-1]])                                                    \n",
    "        # settings_dict.append({\"color\":\"m\", \"linestyle\":\"--\", \"marker\":\"o\", \"label\":\"qcnn\"})\n",
    "        self.results_list_shots_vs_n.append([shots_li, results_error_li, results_error_point, settings_dict])\n",
    "\n",
    "ins_plotdata = PlotData(qht=ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\beta_n$ vs. $\\alpha_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_plotdata.get_results_alpha_vs_beta(1, \"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.plot_alpha_vs_beta(*ins_plotdata.results_list_alpha_vs_beta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $n$ vs. $\\beta_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_plotdata.get_results_beta_vs_n(20, \"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [0.3,0.1,0.05]:\n",
    "    ins.plot_beta_vs_n(alpha, *ins_plotdata.results_list_beta_vs_n[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $n$ vs. training shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_plotdata.get_results_shots_vs_n(50, \"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [0.3,0.1,0.05]:\n",
    "    ins.plot_shots_vs_n(a, a, *ins_plotdata.results_list_shots_vs_n[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc_3.11_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
